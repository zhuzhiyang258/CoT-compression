#!/bin/bash

# LoRAæƒé‡åˆå¹¶å¯åŠ¨è„šæœ¬
# ç”¨æ³•: bash sft/scripts/merge_lora.sh [LORA_ADAPTER_PATH] [OUTPUT_DIR] [OPTIONS]

set -e

echo "ğŸ”— LoRAæƒé‡åˆå¹¶å·¥å…·"
echo "============================================"

# é»˜è®¤å‚æ•°
DEFAULT_BASE_MODEL="./models/Qwen3-4B-Chat"
DEFAULT_LORA_ADAPTER="./sft/outputs/training/test_run/lora_adapters"
DEFAULT_OUTPUT_DIR="./sft/outputs/merged_models/default"
DEFAULT_TORCH_DTYPE="bfloat16"

# è§£æå‘½ä»¤è¡Œå‚æ•°
BASE_MODEL=${1:-$DEFAULT_BASE_MODEL}
LORA_ADAPTER=${2:-$DEFAULT_LORA_ADAPTER}
OUTPUT_DIR=${3:-$DEFAULT_OUTPUT_DIR}
TORCH_DTYPE=${4:-$DEFAULT_TORCH_DTYPE}
VALIDATE=${5:-"true"}

echo "é…ç½®å‚æ•°:"
echo "  åŸºç¡€æ¨¡å‹: $BASE_MODEL"
echo "  LoRAé€‚é…å™¨: $LORA_ADAPTER"
echo "  è¾“å‡ºç›®å½•: $OUTPUT_DIR"
echo "  æ•°æ®ç±»å‹: $TORCH_DTYPE"
echo "  éªŒè¯æ¨¡å‹: $VALIDATE"
echo "============================================"

# æ£€æŸ¥ä¾èµ–
if ! command -v uv &> /dev/null; then
    echo "âŒ UVåŒ…ç®¡ç†å™¨æœªæ‰¾åˆ°ï¼Œè¯·å…ˆå®‰è£…UV"
    echo "å®‰è£…å‘½ä»¤: curl -LsSf https://astral.sh/uv/install.sh | sh"
    exit 1
fi

# æ£€æŸ¥åŸºç¡€æ¨¡å‹
if [ ! -d "$BASE_MODEL" ]; then
    echo "âŒ åŸºç¡€æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: $BASE_MODEL"
    exit 1
fi

# æ£€æŸ¥LoRAé€‚é…å™¨
if [ ! -d "$LORA_ADAPTER" ]; then
    echo "âŒ LoRAé€‚é…å™¨ç›®å½•ä¸å­˜åœ¨: $LORA_ADAPTER"
    echo "è¯·å…ˆå®ŒæˆLoRAè®­ç»ƒï¼Œæˆ–æŒ‡å®šæ­£ç¡®çš„é€‚é…å™¨è·¯å¾„"
    exit 1
fi

# æ£€æŸ¥é€‚é…å™¨é…ç½®æ–‡ä»¶
if [ ! -f "$LORA_ADAPTER/adapter_config.json" ]; then
    echo "âŒ LoRAé€‚é…å™¨é…ç½®æ–‡ä»¶ç¼ºå¤±: $LORA_ADAPTER/adapter_config.json"
    exit 1
fi

# æ£€æŸ¥GPUçŠ¶æ€
echo "ğŸ® GPUçŠ¶æ€æ£€æŸ¥..."
if command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits | head -2
    echo ""
else
    echo "âš ï¸  nvidia-smiä¸å¯ç”¨ï¼Œæ— æ³•æ£€æŸ¥GPUçŠ¶æ€"
fi

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=1  # ä½¿ç”¨GPU 1
export TOKENIZERS_PARALLELISM=false
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "$OUTPUT_DIR"

echo "ğŸš€ å¼€å§‹LoRAæƒé‡åˆå¹¶..."

# æ„å»ºåˆå¹¶å‘½ä»¤
MERGE_CMD="uv run python sft/scripts/merge_lora.py"
MERGE_CMD="$MERGE_CMD --base_model \"$BASE_MODEL\""
MERGE_CMD="$MERGE_CMD --lora_adapter \"$LORA_ADAPTER\""
MERGE_CMD="$MERGE_CMD --output_dir \"$OUTPUT_DIR\""
MERGE_CMD="$MERGE_CMD --torch_dtype \"$TORCH_DTYPE\""

if [ "$VALIDATE" = "true" ]; then
    MERGE_CMD="$MERGE_CMD --validate"
    MERGE_CMD="$MERGE_CMD --test_prompt \"è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼Œå¹¶è§£é‡Šä½ çš„åŠŸèƒ½ã€‚\""
fi

echo "æ‰§è¡Œå‘½ä»¤: $MERGE_CMD"
echo ""

# æ‰§è¡Œåˆå¹¶
eval $MERGE_CMD

# æ£€æŸ¥åˆå¹¶ç»“æœ
if [ $? -eq 0 ]; then
    echo ""
    echo "============================================"
    echo "âœ… LoRAæƒé‡åˆå¹¶å®Œæˆï¼"
    echo ""
    echo "ğŸ“ åˆå¹¶åæ¨¡å‹ä½ç½®: $OUTPUT_DIR"
    echo ""
    echo "ğŸ“‹ è¾“å‡ºç›®å½•å†…å®¹:"
    ls -la "$OUTPUT_DIR" | head -10
    echo ""
    
    # è®¡ç®—æ¨¡å‹å¤§å°
    if command -v du &> /dev/null; then
        MODEL_SIZE=$(du -sh "$OUTPUT_DIR" | cut -f1)
        echo "ğŸ“¦ æ¨¡å‹å¤§å°: $MODEL_SIZE"
    fi
    
    echo ""
    echo "ğŸ¯ ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹:"
    echo "1. æ¨ç†æµ‹è¯•:"
    echo "   python -c \"from transformers import AutoTokenizer, AutoModelForCausalLM; tokenizer = AutoTokenizer.from_pretrained('$OUTPUT_DIR', trust_remote_code=True); model = AutoModelForCausalLM.from_pretrained('$OUTPUT_DIR', trust_remote_code=True)\""
    echo ""
    echo "2. vLLMæœåŠ¡å™¨:"
    echo "   vllm serve '$OUTPUT_DIR' --port 8000"
    echo ""
    echo "============================================"
else
    echo ""
    echo "âŒ LoRAæƒé‡åˆå¹¶å¤±è´¥ï¼"
    echo "è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•"
    exit 1
fi